# Object-Style-Changer

This is my art185 project. This program requires the user go to https://pjreddie.com/darknet/yolo/ and follow the instructions to download yolov3. (When I tried to push darknet to git it gave me an issue about uploading a .git but the terminal instructions for yolo are very straightforward.) Replace your installed image.c (from /darknet/src/image.c) with the one in this github (it replaces printf("%s: %.0f%%\n", names[j], dets[i].prob[j]*100); in the function draw_directions with printf("%s\n", names[j]); as you don't need to save the confidence values as well as adding the line printf("%d, %d, %d, %d\n", left, right, top, bot); just before the draw_box_width call later in the same function to save the box coordinates.) Running the make command in terminal will apply your changes in image.c to yolo. The github for yolo can found at https://github.com/pjreddie/darknet.

The test folder contains the original picture and all of the pictures generated by my code. The style test folder contains the isolated objects, some styles, and the new style shifted objects (note that a style shifted background (mainComp7) is in the main folder while the other style change pics are in the /mods/ folder.) mods/ has style changes where all objects of the same type have the same style while /mods/varied/ has each picture with a differnt style. https://reiinakano.github.io/fast-style-transfer-deeplearnjs/ ran the style transfer and provided a few styles not in the set of paintings included in /style test/. The github for this demo can be found at https://github.com/reiinakano/fast-style-transfer-deeplearnjs.

Project.ipynb should have the os.system function call uncommented so you don't have to run yolo from the terminal.

As seen in the presentaion, the object recognition, style changer, and picture remapper (place modified objects back over original picture) are all working well.

I made several attempts at smoothing the parts of the image where styles change. Unfortunately, after numerous attempts, the result was either a grayscale picture of the input or complete static vaugely resembling the original image as seen in test/smoothfail.jpg. My plan was to find a good filter/convolution/kernel, then take the parts of the image just inside & outside the object border and replace the same pixels in the original image the same way that the style shifted objects were placed into the original picture but, despite my sporadic testing, I was unable to find a suitable method in between my other finals. Since I was unable to smooth the image, I did not attempt my stretch target of applying this process to a video.

madImg1.jpg through madImg4.jpg in the test folder show the final (successful) result of the program with differing style schemes. madImg1 & 2 use the original background in comparision to 3 & 4s modified picture. Likewise, madImg1 & 3 use the same style for every instance of the same object while 2 & 4 have a different style for every object.
